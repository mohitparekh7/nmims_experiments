# -*- coding: utf-8 -*-
"""Exp7_N029_ML

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p5EcTqtiKizFV8soDpUO8gO9NtTDjyGa
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

df=pd.read_csv('heart (1).csv')
df.head()

"""# Data contains;

        age - age in years
        sex - (1 = male; 0 = female)
        cp - chest pain type
        trestbps - resting blood pressure (in mm Hg on admission to the hospital)
        chol - serum cholestoral in mg/dl
        fbs - (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)
        restecg - resting electrocardiographic results
        thalach - maximum heart rate achieved
        exang - exercise induced angina (1 = yes; 0 = no)
        oldpeak - ST depression induced by exercise relative to rest
        slope - the slope of the peak exercise ST segment
        ca - number of major vessels (0-3) colored by flourosopy
        thal - 3 = normal; 6 = fixed defect; 7 = reversable defect
        target - have disease or not (1=yes, 0=no)

# Data Exploration
"""

df.target.value_counts()

sns.countplot(x="target",data=df,palette="bwr")
plt.show()

countNoDisease = len(df[df.target == 0])
countHaveDisease = len(df[df.target == 1])
print("Percentage of Patients Haven't Heart Disease: {:.2f}%".format((countNoDisease / (len(df.target))*100)))
print("Percentage of Patients Have Heart Disease: {:.2f}%".format((countHaveDisease / (len(df.target))*100)))

sns.countplot(x='sex', data=df, palette="mako_r")
plt.xlabel("Sex (0 = female, 1= male)")
plt.show()

countFemale = len(df[df.sex==0])
countMale = len(df[df.sex==1])
# print(countFemale,countMale)
percentageFemales = ( countFemale / (len(df.sex))*100)
percentageMales = ( countMale / (len(df.sex))*100)
print("Percentage of Female Patients: {:.2f}%".format((percentageFemales)))
print("Percentage of Male Patients: {:.2f}%".format((percentageMales)))

"""**Statistical description about the data**"""

df.describe()

df.info()

pd.crosstab(df.sex,df.target).plot(kind="bar",figsize=(15,6),color=['#1CA53B','#AA1111' ])
plt.title('Heart Disease Frequency for Sex')
plt.xlabel('Sex (0 = Female, 1 = Male)')
plt.xticks(rotation=0)
plt.legend(["Haven't Disease", "Have Disease"])
plt.ylabel('Frequency')
plt.show()

#heart disease frequency for age
pd.crosstab(df.age,df.target).plot(kind="bar",figsize=(15,6),color=['#1CA53B','#AA1111' ])
plt.title('Heart Disease Frequency for Age')
plt.xlabel('Age')
plt.xticks(rotation=0)
plt.legend(["Dont have Disease", "Have Disease"])
plt.ylabel('Frequency')
plt.show()

#  Heart Disease frequency for Slope
pd.crosstab(df.slope,df.target).plot(kind="bar",figsize=(15,6),color=['#1CA53B','#AA1111' ])
plt.title('Heart Disease Frequency for Slope')
plt.xlabel('Slope')
plt.xticks(rotation=0)
plt.legend(["Dont have Disease", "Have Disease"])
plt.ylabel('Frequency')
plt.show()

plt.scatter(x=df.age[df.target==1], y=df.thalach[(df.target==1)], c="red")
plt.scatter(x=df.age[df.target==0], y=df.thalach[(df.target==0)])
plt.legend(["Disease", "Not Disease"])
plt.xlabel("Age")
plt.ylabel("Maximum Heart Rate")
plt.show()

#Heart Disease Frequency According To FBS
pd.crosstab(df.fbs,df.target).plot(kind="bar",figsize=(15,6),color=['#1CA53B','#AA1111' ])
plt.title('Heart Disease Frequency for FBS')
plt.xlabel('FBS')
plt.xticks(rotation=0)
plt.legend(["Dont have Disease", "Have Disease"])
plt.ylabel('Frequency')
plt.show()

#Heart Disease Frequency According To Chest Pain Type
pd.crosstab(df.cp,df.target).plot(kind="bar",figsize=(15,6),color=['#1CA53B','#AA1111' ])
plt.title('Heart Disease Frequency for Chest Pain')
plt.xlabel('Chest Pain')
plt.xticks(rotation=0)
plt.legend(["Dont have Disease", "Have Disease"])
plt.ylabel('Frequency')
plt.show()

a = pd.get_dummies(df['cp'], prefix = "cp")
b = pd.get_dummies(df['thal'], prefix = "thal")
c = pd.get_dummies(df['slope'], prefix = "slope")

a

b

c

frames = [df, a, b, c]
df = pd.concat(frames, axis = 1)
df.head()

df = df.drop(columns = ['cp', 'thal', 'slope'])
df.head()

#split X and Y variables
X = df[['age','sex','trestbps','chol','fbs','restecg','thalach','exang','oldpeak']]
Y = df['target']

#Normalize features
scaler = StandardScaler()
scaler.fit(X)
X = scaler.transform(X)

#train test split (80:20)
x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.2, random_state = 42)

accuracies = {}

lr = LogisticRegression()
lr.fit(x_train,y_train)
acc = lr.score(x_test,y_test)*100

accuracies['Logistic Regression'] = acc
print("Test Accuracy {:.2f}%".format(acc))

"""# K-Nearest Neighbour (KNN) Classification

Let's see what will be score if we use KNN algorithm.

# ![image.png](attachment:image.png)
"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors = 2)  # n_neighbors means k
knn.fit(x_train, y_train)
prediction = knn.predict(x_test)

print("{} NN Score: {:.2f}%".format(2, knn.score(x_test, y_test.T)*100))

# try ro find best k value
scoreList = []
for i in range(1,20):
    knn2 = KNeighborsClassifier(n_neighbors = i)  # n_neighbors means k
    knn2.fit(x_train,y_train)
    scoreList.append(knn2.score(x_test,y_test.T))
    
plt.plot(range(1,20), scoreList)
plt.xticks(np.arange(1,20,1))
plt.xlabel("K value")
plt.ylabel("Score")
plt.show()

acc = max(scoreList)*100
accuracies['KNN'] = acc
print("Maximum KNN Score is {:.2f}%".format(acc))

"""# Support Vector Machine (SVM) Algorithm"""

from sklearn.svm import SVC

svm = SVC(random_state = 1)
svm.fit(x_train,y_train)

acc = svm.score(x_test,y_test)*100
accuracies['SVM'] = acc
print("Test Accuracy of SVM Algorithm: {:.2f}%".format(acc))

"""# Naive Bayes Algorithm"""

from sklearn.naive_bayes import GaussianNB
nb = GaussianNB()
nb.fit(x_train,y_train)

acc = nb.score(x_test,y_test.T)*100
accuracies['Naive Bayes'] = acc
print("Accuracy of Naive Bayes: {:.2f}%".format(acc))

"""# Decision Tree Algorithm

# ![image.png](attachment:image.png)
"""

from sklearn.tree import DecisionTreeClassifier
dtc = DecisionTreeClassifier()
dtc.fit(x_train,y_train)
acc = dtc.score(x_test,y_test)*100
accuracies['Decision Tree'] = acc
print("Decision Tree Test Accuracy {:.2f}%".format(acc))

"""# Random Forest Classification"""

# Random Forest Classification
from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(n_estimators = 1000, random_state = 1)
rf.fit(x_train,y_train)

acc = rf.score(x_test,y_test.T)*100
accuracies['Random Forest'] = acc
print("Random Forest Algorithm Accuracy Score : {:.2f}%".format(acc))

"""# Comparing Models"""

colors = ["purple", "green", "orange", "magenta","#CFC60E","#0FBBAE"]

sns.set_style("whitegrid")
plt.figure(figsize=(16,5))
plt.yticks(np.arange(0,100,10))
plt.ylabel("Accuracy %")
plt.xlabel("Algorithms")
sns.barplot(x=list(accuracies.keys()), y=list(accuracies.values()), palette=colors)
plt.show()

"""# Confusion Matrix"""

# Predicted values
y_head_lr = lr.predict(x_test)
knn3 = KNeighborsClassifier(n_neighbors = 3)
knn3.fit(x_train, y_train)
y_head_knn = knn3.predict(x_test)
y_head_svm = svm.predict(x_test)
y_head_nb = nb.predict(x_test)
y_head_dtc = dtc.predict(x_test)
y_head_rf = rf.predict(x_test)

from sklearn.metrics import confusion_matrix

cm_lr = confusion_matrix(y_test,y_head_lr)
cm_knn = confusion_matrix(y_test,y_head_knn)
cm_svm = confusion_matrix(y_test,y_head_svm)
cm_nb = confusion_matrix(y_test,y_head_nb)
cm_dtc = confusion_matrix(y_test,y_head_dtc)
cm_rf = confusion_matrix(y_test,y_head_rf)

plt.figure(figsize=(24,12))

plt.suptitle("Confusion Matrixes",fontsize=24)
plt.subplots_adjust(wspace = 0.4, hspace= 0.4)

plt.subplot(2,3,1)
plt.title("Logistic Regression Confusion Matrix")
sns.heatmap(cm_lr,annot=True,cmap="Blues",fmt="d",cbar=False, annot_kws={"size": 24})

plt.subplot(2,3,2)
plt.title("K Nearest Neighbors Confusion Matrix")
sns.heatmap(cm_knn,annot=True,cmap="Blues",fmt="d",cbar=False, annot_kws={"size": 24})

plt.subplot(2,3,3)
plt.title("Support Vector Machine Confusion Matrix")
sns.heatmap(cm_svm,annot=True,cmap="Blues",fmt="d",cbar=False, annot_kws={"size": 24})

plt.subplot(2,3,4)
plt.title("Naive Bayes Confusion Matrix")
sns.heatmap(cm_nb,annot=True,cmap="Blues",fmt="d",cbar=False, annot_kws={"size": 24})

plt.subplot(2,3,5)
plt.title("Decision Tree Classifier Confusion Matrix")
sns.heatmap(cm_dtc,annot=True,cmap="Blues",fmt="d",cbar=False, annot_kws={"size": 24})

plt.subplot(2,3,6)
plt.title("Random Forest Confusion Matrix")
sns.heatmap(cm_rf,annot=True,cmap="Blues",fmt="d",cbar=False, annot_kws={"size": 24})

plt.show()

